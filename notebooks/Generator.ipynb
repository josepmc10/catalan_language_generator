{"cells":[{"cell_type":"markdown","metadata":{"id":"PteAySB24sqN"},"source":["# Generator"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20490,"status":"ok","timestamp":1655275557009,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"vIUg1kri4ppF","outputId":"4719e0e3-b705-4eb4-c8e3-842153b0ce05"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","data_path = '/content/drive/Shareddrives/DeepLearning_2022/Final-Project/input/'\n","model_path = '/content/drive/Shareddrives/DeepLearning_2022/Final-Project/models/'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4513,"status":"ok","timestamp":1655275561515,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"O0IPKTTl46Sz","outputId":"d9212f7f-cd8c-4be2-bdb8-5659dd24fa8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of different words 30592\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch\n","def vocabulary(words):\n","  \"\"\"\n","  Given a plain text in a list returns a list with all the different words.\n","  \"\"\"\n","  vocab = set()\n","  for word in words:\n","    if word not in vocab:\n","      vocab.add(word)\n","\n","  return list(vocab)\n","\n","#Decide what to do with words that are not in the vocabulary\n","def text_to_seq(text,vocab,add_n = False):\n","  \"\"\"\n","  Given a text split it and a vocabulary, return a list of numbers that refers \n","  to the index position of each word in the vocabulary.\n","  \"\"\"\n","  sequence = []\n","  for word in text:\n","    if word != \"\":\n","      sequence.append(vocab.index(word))\n","\n","  return torch.tensor(sequence)\n","\n","with open(data_path + \"llibres_dataset_v3.txt\",\"r\") as f:\n","  dataset = \"\"\n","  for line in f:\n","    dataset += line \n","\n","for_vocabulary = dataset.replace(\"\\n\",\" \")\n","vocab = vocabulary(for_vocabulary.split(\" \"))\n","print(\"Number of different words\",len(vocab))"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1655275932285,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"Z0inA6cx47n8"},"outputs":[],"source":["class LSTM_model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size,dropout):\n","        super(LSTM_model, self).__init__()\n","        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm1 = nn.LSTM(input_size, hidden_size)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        #self.sigm = nn.Sigmoid()\n","        #self.dropout = nn.Dropout(dropout)\n","\n","    def zero_hidden(self):\n","        # Initialize lstm states with zeros\n","        return (torch.zeros(1, 1, hidden_dim).cuda(),\n","                torch.zeros(1, 1, hidden_dim).cuda())\n","\n","    def forward(self, input):\n","        x = self.embed(input).unsqueeze(1) #We need the unsqueze to introduce the new dimension\n","        output_lstm, states_lstm = self.lstm1(x, self.zero_hidden())\n","        output_lstm, states_lstm = self.lstm2(output_lstm, self.zero_hidden())\n","        #output_lstm = self.dropout(output_lstm)\n","        output_fc = self.fc(output_lstm)\n","        #out = self.sigm(output_fc)\n","        return output_fc, output_lstm, states_lstm"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":545,"status":"ok","timestamp":1655275934328,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"teNuxX0K5twB"},"outputs":[],"source":["embedding_dim = 400\n","hidden_dim = 400\n","vocab_size = len(vocab)\n","#vocab_size = 14379\n","LSTM_model = LSTM_model(embedding_dim, hidden_dim, vocab_size,dropout=None).cuda()"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3148,"status":"ok","timestamp":1655275938704,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"8y2b_TrE5agU","outputId":"c0efe461-32f9-4507-8ac6-551f39f5a027"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["LSTM_model.load_state_dict(torch.load(model_path+'/language_generator.ckpt'))"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1655275941323,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"ySXzwuCb6BMp"},"outputs":[],"source":["def tensor_to_str(tensor,vocab):\n","  text = \"\"\n","  for elem in tensor:\n","    text += \" \"+ vocab[int(elem)]\n","  return text\n"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1655276284656,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"MdoPcpYo5-FX","outputId":"1f8ce9ad-2456-4dd2-8166-64ee0fc21d79"},"outputs":[{"name":"stdout","output_type":"stream","text":[" estic menu grinyolant germanivolament peculiar pets\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}],"source":["\n","sig = nn.Softmax()\n","\n","def generator(model,n_words,vocab,seed):\n","  result = text_to_seq(seed.split(\" \"),vocab).cuda()\n","  final_list = list(result)\n","  for n in range(n_words):\n","    #Instead of max sample\n","    #print(torch.tensor(final_list))\n","    val = model(torch.tensor(final_list).cuda())[0][0]\n","    val = sig(val)\n","    final_list.append(val.multinomial(num_samples=1))\n","  return tensor_to_str(final_list,vocab)\n","seed = \"estic\"\n","print(generator(LSTM_model,5,vocab,seed))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XKtZnJMmIqOC"},"outputs":[],"source":["# Input / Output\n","#a mi m agraden els llibres perque soc / automata\n","\n","# el ocell / oest despatxava absorcions ficantse\n","\n","#tu ets / desplaent\n","\n","# tu ets / becker pressentia\n","\n","# nosaltres som / clausules meno ario molestaven emmidonats"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNUrZkPcLdYX6x4tKtrP+1t","collapsed_sections":[],"name":"Generator.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
