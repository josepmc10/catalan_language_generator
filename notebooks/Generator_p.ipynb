{"cells":[{"cell_type":"markdown","metadata":{"id":"PteAySB24sqN"},"source":["# Generator"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25148,"status":"ok","timestamp":1655215475599,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"vIUg1kri4ppF","outputId":"058a0e8e-fdeb-4beb-cf00-bcca5443eecb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","data_path = '/content/drive/Shareddrives/DeepLearning_2022/Final-Project/input/'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7282,"status":"ok","timestamp":1655215482874,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"O0IPKTTl46Sz","outputId":"906d13ab-c26e-44dc-d657-f34cf463207f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of poems 290\n","Number of words in total 35034\n","Number of words of the vocabulary 7554\n"]}],"source":["import torch\n","import re\n","import torch.nn as nn\n","import torch\n","def vocabulary(words):\n","  \"\"\"\n","  Given a plain text in a list returns a list with all the different words.\n","  \"\"\"\n","  vocab = set()\n","  for word in words:\n","    if word not in vocab:\n","      vocab.add(word)\n","\n","  return list(vocab)\n","\n","def preprocessing_text(text,n = True):\n","  #To lowecase the text\n","  result = text.lower()\n","  #Eliminate digits\n","  result = re.sub(r'\\d+', '', result)\n","  #Eliminate \\n\n","  result = re.sub(\"\\n\\n\",\"\",result)\n","  if n:\n","    result = re.sub(\"\\n\",\" \",result)\n","  #Considering \\n as one more word\n","  else:\n","    result = re.sub(\"\\n\",\" \\n \",result)\n","  #Eliminate \\t\n","  result = re.sub(\"\\t\",\" \",result)\n","\n","  #Eliminate any punctuation and symbol\n","  result = re.sub(\"[\\[\\]\\(\\)\\\"=!º.,¿?;:«»*_]\",' ',result)\n","  #Eliminate multiple white spaces\n","  result = re.sub(' +', ' ', result)\n","\n","  return result\n","\n","#Decide what to do with words that are not in the vocabulary\n","def text_to_seq(text,vocab,add_n = False):\n","  \"\"\"\n","  Given a text split it and a vocabulary, return a list of numbers that refers \n","  to the index position of each word in the vocabulary.\n","  \"\"\"\n","  sequence = []\n","  for word in text:\n","    if word != \"\":\n","      sequence.append(vocab.index(word))\n","\n","  return torch.tensor(sequence)\n","\n","with open(data_path + \"poesia_v3.txt\",\"r\") as f:\n","  poesia = \"\"\n","  for line in f:\n","    poesia += line\n","\n","poe = re.sub(\"--\",\"%\",poesia)\n","poesias_list = poe.split(\"%\")\n","\n","poesies_proc = []\n","poesies_vocab = []\n","for poem in poesias_list:\n","  poesies_vocab.append(preprocessing_text(poem))\n","  poesies_proc.append(preprocessing_text(poem,False))\n","\n","words = \" \".join(poesies_proc).split(\" \")\n","vocab = vocabulary(words)[1:]\n","print(\"Number of poems\",len(poesias_list))\n","print(\"Number of words in total\",len(words))\n","print(\"Number of words of the vocabulary\",len(vocab))"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1655215482874,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"Z0inA6cx47n8"},"outputs":[],"source":["class LSTM_model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size,dropout):\n","        super(LSTM_model, self).__init__()\n","        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm1 = nn.LSTM(input_size, hidden_size)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n","        #self.lstm3 = nn.LSTM(hidden_size, hidden_size)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        #self.sigm = nn.Sigmoid()\n","        #self.dropout = nn.Dropout(dropout)\n","\n","    def zero_hidden(self):\n","        # Initialize lstm states with zeros\n","        return (torch.zeros(1, 1, hidden_dim).cuda(),\n","                torch.zeros(1, 1, hidden_dim).cuda())\n","\n","    def forward(self, input):\n","        x = self.embed(input).unsqueeze(1) #We need the unsqueze to introduce the new dimension\n","        output_lstm, states_lstm = self.lstm1(x, self.zero_hidden())\n","        output_lstm, states_lstm = self.lstm2(output_lstm, self.zero_hidden())\n","        #output_lstm, states_lstm = self.lstm3(output_lstm, self.zero_hidden())\n","        #output_lstm = self.dropout(output_lstm)\n","        out = self.fc(output_lstm)\n","        #out = self.sigm(out)\n","        return out, output_lstm, states_lstm"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11796,"status":"ok","timestamp":1655215494663,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"teNuxX0K5twB"},"outputs":[],"source":["embedding_dim = 400\n","hidden_dim = 400\n","vocab_size = len(vocab)\n","\n","LSTM_model = LSTM_model(embedding_dim, hidden_dim, vocab_size,dropout=None).cuda()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2207,"status":"ok","timestamp":1655215496864,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"8y2b_TrE5agU","outputId":"35cf2e77-e898-4d93-8880-c703a90321bc"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["LSTM_model.load_state_dict(torch.load(data_path+'/poem_generator_1.2174loss.ckpt'))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1655215496865,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"ySXzwuCb6BMp"},"outputs":[],"source":["def tensor_to_str(tensor,vocab):\n","  text = \"\"\n","  for elem in tensor:\n","    text += \" \"+ vocab[int(elem)]\n","  return text\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":928,"status":"ok","timestamp":1655215541113,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"},"user_tz":-120},"id":"MdoPcpYo5-FX","outputId":"815df8e5-8e87-4b5d-8ece-430aa29a71ce"},"outputs":[{"name":"stdout","output_type":"stream","text":[" el deu del mon tres vianant enfonsaren sola mant\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}],"source":["\n","sig = nn.Softmax()\n","\n","def generator(model,n_words,vocab,seed):\n","  result = text_to_seq(seed.split(\" \"),vocab).cuda()\n","  final_list = list(result)\n","  for n in range(n_words):\n","    #Instead of max sample\n","    #print(torch.tensor(final_list))\n","    val = model(torch.tensor(final_list).cuda())[0][0]\n","    val = sig(val)\n","    final_list.append(val.multinomial(num_samples=1))\n","  return tensor_to_str(final_list,vocab)\n","seed = \"el deu del mon\"\n","print(generator(LSTM_model,5,vocab,seed))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeRgzKbykbVe"},"outputs":[],"source":["#jo vull escalfor ulls soterràrem quaranta aixecar-la"]}],"metadata":{"accelerator":"GPU","colab":{"name":"Generator_p.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
