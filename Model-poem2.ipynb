{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model-poem2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"Rxgp7W7bgcS9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DA6w3KONgYZb","executionInfo":{"status":"ok","timestamp":1654174076627,"user_tz":-120,"elapsed":23670,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"7f7a72e5-a169-4a49-97bc-d584332abe84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","import random\n","from torch import nn\n","import torch\n","import nltk\n","import string\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torchtext\n","import torch.nn as nn\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import Vocab\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","\n","from collections import Counter\n","\n","drive.mount('/content/drive/')\n","data_path = '/content/drive/Shareddrives/DeepLearning_2022/Final-Project/Data/'"]},{"cell_type":"code","source":["\n","def preprocessing_text(text,n = True):\n","  #To lowecase the text\n","  result = text.lower()\n","  #Eliminate digits\n","  result = re.sub(r'\\d+', '', result)\n","  #Eliminate \\n\n","  result = re.sub(\"\\n\\n\",\"\",result)\n","  if n:\n","    result = re.sub(\"\\n\",\" \",result)\n","  #Considering \\n as one more word\n","  else:\n","    result = re.sub(\"\\n\",\" \\n \",result)\n","  #Eliminate \\t\n","  result = re.sub(\"\\t\",\" \",result)\n","\n","  #Eliminate any punctuation and symbol\n","  result = re.sub(\"[\\[\\]\\(\\)\\\"=!º.,¿?;:«»*_]\",' ',result)\n","  #Eliminate multiple white spaces\n","  result = re.sub(' +', ' ', result)\n","\n","  return result\n","\n","def vocabulary(words):\n","  \"\"\"\n","  Given a plain text in a list returns a list with all the different words.\n","  \"\"\"\n","  vocab = set()\n","  for word in words:\n","    if word not in vocab:\n","      vocab.add(word)\n","\n","  return list(vocab)\n","\n","#Decide what to do with words that are not in the vocabulary\n","def text_to_seq(text,vocab,add_n = False):\n","  \"\"\"\n","  Given a text split it and a vocabulary, return a list of numbers that refers \n","  to the index position of each word in the vocabulary.\n","  \"\"\"\n","  sequence = []\n","  for word in text:\n","    if word != \"\":\n","      sequence.append(vocab.index(word))\n","  if add_n:\n","    sequence.append(vocab.index(\"\\n\"))\n","\n","  return torch.tensor(sequence)\n","\n"],"metadata":{"id":"E-dAkoYdgq9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(data_path + \"poesia_v3.txt\",\"r\") as f:\n","  poesia = \"\"\n","  for line in f:\n","    poesia += line\n","\n","poe = re.sub(\"--\",\"%\",poesia)\n","poesias_list = poe.split(\"%\")\n","\n","poesies_proc = []\n","poesies_vocab = []\n","for poem in poesias_list:\n","  poesies_vocab.append(preprocessing_text(poem))\n","  poesies_proc.append(preprocessing_text(poem,False))\n","\n","words = \" \".join(poesies_proc).split(\" \")\n","vocab = vocabulary(words)[1:]\n","print(\"Number of poems\",len(poesias_list))\n","print(\"Number of words in total\",len(words))\n","print(\"Number of words of the vocabulary\",len(vocab))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ykrQ-xogbyB","executionInfo":{"status":"ok","timestamp":1654174078416,"user_tz":-120,"elapsed":1792,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"d074179f-1bf1-4a71-9236-824ca3bff55a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of poems 290\n","Number of words in total 35034\n","Number of words of the vocabulary 7554\n"]}]},{"cell_type":"markdown","source":["## Defining the training data (n-grams)"],"metadata":{"id":"91IGjCwZoM4C"}},{"cell_type":"code","source":["def data_process(corpus, vocab):\n","    data = list()\n","    for text in corpus:\n","      for paragraph in text.split(\" \\n \"):\n","        token_list = text_to_seq(paragraph.split(\" \"),vocab,True)\n","        for i in range(1, len(token_list)):\n","            n_gram_seq = torch.tensor(token_list[:i+1], dtype=torch.long)\n","            data.append(n_gram_seq)\n","    return data"],"metadata":{"id":"TyU2ZM6ToO_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = data_process(poesies_proc, vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUUGhsbVtoJH","executionInfo":{"status":"ok","timestamp":1654174083627,"user_tz":-120,"elapsed":2812,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"32d657a7-5a2e-4f6b-b353-4b1df9e2692c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"]}]},{"cell_type":"code","source":["X = [i[:-1] for i in train_data]   # taking all the words except the last in the input set\n","y = [i[-1] for i in train_data]    # taking last words in the output set\n","print(\"X shape\",len(X))\n","print(\"y shape\",len(y))\n","print(X[0],y[0])"],"metadata":{"id":"7W2_cXP-tuOt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654174083629,"user_tz":-120,"elapsed":12,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"830b5d3c-cab8-47e6-ecb7-18ce82db390f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X shape 30331\n","y shape 30331\n","tensor([6049]) tensor(7387)\n"]}]},{"cell_type":"code","source":["\n","y = torch.from_numpy(np.array(y))\n","print(y)"],"metadata":{"id":"wYzWfDDBuhXO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654174083950,"user_tz":-120,"elapsed":329,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"c58c17dc-2b1b-485c-9268-3a0783b7a859"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([7387, 6404, 4116,  ...,  378, 6427, 3729])\n"]}]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"_SfWmquVgeqX"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"klZmIAguvBAs","executionInfo":{"status":"ok","timestamp":1654174085468,"user_tz":-120,"elapsed":232,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"f998c2ef-4b40-4639-8130-c9a7c3054916"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","class LSTM_model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size,dropout):\n","        super(LSTM_model, self).__init__()\n","        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm1 = nn.LSTM(input_size, hidden_size)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n","        self.lstm3 = nn.LSTM(hidden_size, hidden_size)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        #self.sigm = nn.Sigmoid()\n","        #self.dropout = nn.Dropout(dropout)\n","\n","    def zero_hidden(self):\n","        # Initialize lstm states with zeros\n","        return (torch.zeros(1, 1, hidden_dim).cuda(),\n","                torch.zeros(1, 1, hidden_dim).cuda())\n","\n","    def forward(self, input):\n","        x = self.embed(input).unsqueeze(1) #We need the unsqueze to introduce the new dimension\n","        output_lstm, states_lstm = self.lstm1(x, self.zero_hidden())\n","        output_lstm, states_lstm = self.lstm2(output_lstm, self.zero_hidden())\n","        output_lstm, states_lstm = self.lstm3(output_lstm, self.zero_hidden())\n","        #output_lstm = self.dropout(output_lstm)\n","        out = self.fc(output_lstm)\n","        #out = self.sigm(out)\n","        return out, output_lstm, states_lstm"],"metadata":{"id":"4cQUAA-JgfjH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 20\n","embedding_dim = 400\n","hidden_dim = 250\n","vocab_size = len(vocab)\n","\n","LSTM_model = LSTM_model(embedding_dim, hidden_dim, vocab_size,dropout=None).cuda()\n","\n","CE_loss = torch.nn.CrossEntropyLoss() \n","#loss = nn.NLLLoss()\n","\n","optimizer_LSTM = torch.optim.Adam(list(LSTM_model.parameters()), lr=0.0000005,weight_decay=0.001)"],"metadata":{"id":"eTUODNKP3nvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_loop(model, num_epochs, CE_loss, optimizer, X,y):\n","\n","    loss_hist = []\n","    min_loss = float(\"inf\")\n","\n","    for x in range(num_epochs):\n","        print('Epoch: {}'.format(x))\n","        optimizer.zero_grad()\n","        # TRAINING LOOP\n","        for i,instance in enumerate(X):\n","            val = instance.cuda()\n","            #y_aux = np.zeros(len(vocab))\n","            #y_aux[int(y[i])] = 1.0\n","            y_val = y[i].cuda()\n","            #y_val = torch.tensor(y_aux).cuda()\n","            y_hat, _, _ = model(val)\n","            # Calculate loss\n","            #loss = CE_loss(y_hat[0][0], y_val)\n","            loss = CE_loss(y_hat[0][0], y_val)\n","            # Backpropagate\n","            loss.backward()\n","            #Clip gradient\n","            #nn.utils.clip_grad_norm_(model.parameters(), 5)\n","            # Update weights\n","            optimizer.step()\n","        if loss.item() < min_loss:\n","          min_loss = loss.item()\n","          torch.save(LSTM_model.state_dict(), data_path+'/poem_generator_minloss.ckpt')\n","        print('Loss: {:6.4f}'.format(loss.item()))\n","        loss_hist.append(loss.item())\n","    return loss_hist"],"metadata":{"id":"EB4zicHTxAc3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_hist = train_loop(LSTM_model, num_epochs, CE_loss, optimizer_LSTM, X, y)"],"metadata":{"id":"4u4eU3rg3WC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(LSTM_model.state_dict(), data_path+'/poem_generator_0.4222.ckpt')"],"metadata":{"id":"9i96d14oWzGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LSTM_model.load_state_dict(torch.load(data_path + '/poem_generator_minloss.ckpt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNtVcrSfwiAh","executionInfo":{"status":"ok","timestamp":1654180115646,"user_tz":-120,"elapsed":195,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"87c302b0-8cea-4918-dfa8-bfc7ea6631ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":74}]},{"cell_type":"markdown","source":["# Generator"],"metadata":{"id":"cutsmBPp3UbO"}},{"cell_type":"code","source":["def tensor_to_str(tensor,vocab):\n","  text = \"\"\n","  for elem in tensor:\n","    text += \" \"+ vocab[int(elem)]\n","  return text"],"metadata":{"id":"9ngGt1sOYCa6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sig = nn.Sigmoid()"],"metadata":{"id":"GRd_N8qyEb7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generator(model,n_words,vocab,seed):\n","  result = text_to_seq(seed.split(\" \"),vocab).cuda()\n","  final_list = list(result)\n","  for n in range(n_words):\n","    #Instead of max sample\n","    #print(torch.tensor(final_list))\n","    val = model(torch.tensor(final_list).cuda())[0][0]\n","    val = sig(val)\n","    final_list.append(val.multinomial(num_samples=1))\n","    #final_list.append(torch.argmax(val))\n","    #print(tensor_to_str(final_list,vocab))\n","  #print(torch.tensor(final_list))\n","  return tensor_to_str(final_list,vocab)\n","seed = \"jo sóc\"\n","print(generator(LSTM_model,3,vocab,seed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DRJc7OsdXwQC","executionInfo":{"status":"ok","timestamp":1654180235544,"user_tz":-120,"elapsed":247,"user":{"displayName":"PATRÍCIA ROCA","userId":"11897714718527318683"}},"outputId":"79ed8f34-5d8c-4248-a634-de74ebb3792f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" jo sóc d'orgull mai ciutats\n"]}]},{"cell_type":"code","source":["#Improved model\n","\n","#la mort camí els déu com raó rica perquè ran balanguera ens més plors plans qui bellesa és \n","# dona l'amor de\n","\n","# la vida dirà m'enjoio dirà esvaïa brisa llibertat opulenta llibertat lírica realitat somni sóc naixença déu de sang pel goig anar semblaria\n","#la vida frem carrer infidels encara resen mort negre sofisticcada assassines negui creient-me aigua pirineus les davant vençó enveja trontollar platja feria"],"metadata":{"id":"5UPQeqr1RZ_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#First model\n","\n","#la mort em son sa mal l'hora veu si d'amor enrera estaig no tan ho dolç és fent ha pugui ira dolç un\n","\n","#la mar dolça les amor els al es sense anglès dels ben blanc si es tot bocí jo si és tot teu paraula\n","\n","#paraules institució alts al gent és i tu com e us \n","#home vent al no jo quan perquè més si\n","\n","#paraules font somni joia com perd per si o hi honor ulls plors les goig amb que en marriments l'hora sense\n","\n","#la mar ens mira d'amor ja l'hora és crit pregon una del nom ens es veu molt a un més un camí veu de déu cor hom del i la déu amb ara les"],"metadata":{"id":"AaG41VOA9CEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r,_,_ = LSTM_model(X[10].cuda())\n","vals = r[0][0].cpu().detach().numpy()\n","#( r[0][0] - torch.min(r[0][0]) ) / ( torch.max(r[0][0]) - torch.min(r[0][0]) )\n","#(vals - np.min(vals)) / (np.max(vals) - np.min(vals))\n","r[0][0].multinomial(num_samples=1)\n","#torch.argmax(r[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewDzLAv4jnvy","executionInfo":{"status":"ok","timestamp":1654022541970,"user_tz":-120,"elapsed":449,"user":{"displayName":"Josep Monclús","userId":"07284642819118001901"}},"outputId":"3634c816-0de8-4023-b5cf-0a9ca9392c46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([345], device='cuda:0')"]},"metadata":{},"execution_count":204}]},{"cell_type":"code","source":[""],"metadata":{"id":"kEQFKxv8anS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = r[0][0]\n","b = np.zeros(len(vocab),dtype=np.float32)\n","b[int(y[10])] = float(1.0)\n","b = torch.tensor(b).cuda()"],"metadata":{"id":"ASBixb-JIRLh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.log(a).dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Kopc4s7bkHn","executionInfo":{"status":"ok","timestamp":1654022663624,"user_tz":-120,"elapsed":376,"user":{"displayName":"Josep Monclús","userId":"07284642819118001901"}},"outputId":"4ae0a6df-13f5-45d1-8d42-896c1791c659"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":216}]},{"cell_type":"code","source":["b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBGV8gaqblsK","executionInfo":{"status":"ok","timestamp":1654022665478,"user_tz":-120,"elapsed":417,"user":{"displayName":"Josep Monclús","userId":"07284642819118001901"}},"outputId":"07c70fa3-c49d-4283-8e20-4693de86807e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"]},"metadata":{},"execution_count":217}]},{"cell_type":"code","source":["loss(torch.log(a), b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"C-dKYe24a2hs","executionInfo":{"status":"error","timestamp":1654022670945,"user_tz":-120,"elapsed":420,"user":{"displayName":"Josep Monclús","userId":"07284642819118001901"}},"outputId":"fdc25d96-1b7e-499b-84c4-1b83dac18708"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-218-524987429d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2669\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_1d_index\" not implemented for 'Float'"]}]},{"cell_type":"code","source":["#y[10]\n","a = np.zeros(len(vocab))\n","a[1528] = 1\n","tn = torch.tensor(a)\n","print(tn.cuda())\n","print(r[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTAtMGNKIe7d","executionInfo":{"status":"ok","timestamp":1654018040794,"user_tz":-120,"elapsed":7,"user":{"displayName":"Josep Monclús","userId":"07284642819118001901"}},"outputId":"7cbb0679-6051-410f-99f0-27e360fb628f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1., device='cuda:0', dtype=torch.float64)\n","tensor([2.0237e-07, 2.5471e-05, 2.8484e-04,  ..., 7.8355e-05, 2.7058e-07,\n","        3.2904e-01], device='cuda:0', grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"XRpcQg3P3UyK"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"7U4zMBrr3VJD"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"pUPBTg463VeG"}},{"cell_type":"code","source":["\n","class LSTM_model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size,dropout):\n","        super(LSTM_model, self).__init__()\n","        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm1 = nn.LSTM(input_size, hidden_size)\n","        self.lstm2 = nn.LSTM(hidden_size, (hidden_size//2))\n","        self.fc = nn.Linear((hidden_dim//2), output_size)\n","        #self.dropout = nn.Dropout(dropout)\n","\n","    def zero_hidden(self,n_lstm,n_lstm2):\n","        # Initialize lstm states with zeros\n","        return (torch.zeros(1, 1, hidden_dim//n_lstm).cuda(),\n","                torch.zeros(1, 1, hidden_dim//n_lstm2).cuda())\n","\n","    def forward(self, input):\n","        x = self.embed(input).unsqueeze(1) #We need the unsqueze to introduce the new dimension\n","        output_lstm, states_lstm = self.lstm1(x, self.zero_hidden(1,1))\n","        #output_lstm = self.dropout(output_lstm)\n","        output_lstm, states_lstm = self.lstm2(output_lstm, self.zero_hidden(2,2))\n","        #output_lstm = self.dropout(output_lstm)\n","        output_fc = self.fc(output_lstm)\n","        return output_fc, output_lstm, states_lstm"],"metadata":{"id":"BJBse_sk1Knr"},"execution_count":null,"outputs":[]}]}