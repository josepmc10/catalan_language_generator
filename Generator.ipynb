{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNUrZkPcLdYX6x4tKtrP+1t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Generator"],"metadata":{"id":"PteAySB24sqN"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIUg1kri4ppF","executionInfo":{"status":"ok","timestamp":1655275557009,"user_tz":-120,"elapsed":20490,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}},"outputId":"4719e0e3-b705-4eb4-c8e3-842153b0ce05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","data_path = '/content/drive/Shareddrives/DeepLearning_2022/Final-Project/Data/'\n","model_path = '/content/drive/Shareddrives/DeepLearning_2022/Final-Project/models/'"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch\n","def vocabulary(words):\n","  \"\"\"\n","  Given a plain text in a list returns a list with all the different words.\n","  \"\"\"\n","  vocab = set()\n","  for word in words:\n","    if word not in vocab:\n","      vocab.add(word)\n","\n","  return list(vocab)\n","\n","#Decide what to do with words that are not in the vocabulary\n","def text_to_seq(text,vocab,add_n = False):\n","  \"\"\"\n","  Given a text split it and a vocabulary, return a list of numbers that refers \n","  to the index position of each word in the vocabulary.\n","  \"\"\"\n","  sequence = []\n","  for word in text:\n","    if word != \"\":\n","      sequence.append(vocab.index(word))\n","\n","  return torch.tensor(sequence)\n","\n","with open(data_path + \"llibres_dataset_v3.txt\",\"r\") as f:\n","  dataset = \"\"\n","  for line in f:\n","    dataset += line \n","\n","for_vocabulary = dataset.replace(\"\\n\",\" \")\n","vocab = vocabulary(for_vocabulary.split(\" \"))\n","print(\"Number of different words\",len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0IPKTTl46Sz","executionInfo":{"status":"ok","timestamp":1655275561515,"user_tz":-120,"elapsed":4513,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}},"outputId":"d9212f7f-cd8c-4be2-bdb8-5659dd24fa8e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of different words 30592\n"]}]},{"cell_type":"code","source":["class LSTM_model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size,dropout):\n","        super(LSTM_model, self).__init__()\n","        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm1 = nn.LSTM(input_size, hidden_size)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        #self.sigm = nn.Sigmoid()\n","        #self.dropout = nn.Dropout(dropout)\n","\n","    def zero_hidden(self):\n","        # Initialize lstm states with zeros\n","        return (torch.zeros(1, 1, hidden_dim).cuda(),\n","                torch.zeros(1, 1, hidden_dim).cuda())\n","\n","    def forward(self, input):\n","        x = self.embed(input).unsqueeze(1) #We need the unsqueze to introduce the new dimension\n","        output_lstm, states_lstm = self.lstm1(x, self.zero_hidden())\n","        output_lstm, states_lstm = self.lstm2(output_lstm, self.zero_hidden())\n","        #output_lstm = self.dropout(output_lstm)\n","        output_fc = self.fc(output_lstm)\n","        #out = self.sigm(output_fc)\n","        return output_fc, output_lstm, states_lstm"],"metadata":{"id":"Z0inA6cx47n8","executionInfo":{"status":"ok","timestamp":1655275932285,"user_tz":-120,"elapsed":2,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 400\n","hidden_dim = 400\n","vocab_size = len(vocab)\n","#vocab_size = 14379\n","LSTM_model = LSTM_model(embedding_dim, hidden_dim, vocab_size,dropout=None).cuda()"],"metadata":{"id":"teNuxX0K5twB","executionInfo":{"status":"ok","timestamp":1655275934328,"user_tz":-120,"elapsed":545,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["LSTM_model.load_state_dict(torch.load(model_path+'/language_generator.ckpt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8y2b_TrE5agU","executionInfo":{"status":"ok","timestamp":1655275938704,"user_tz":-120,"elapsed":3148,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}},"outputId":"c0efe461-32f9-4507-8ac6-551f39f5a027"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["def tensor_to_str(tensor,vocab):\n","  text = \"\"\n","  for elem in tensor:\n","    text += \" \"+ vocab[int(elem)]\n","  return text\n"],"metadata":{"id":"ySXzwuCb6BMp","executionInfo":{"status":"ok","timestamp":1655275941323,"user_tz":-120,"elapsed":199,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["\n","sig = nn.Softmax()\n","\n","def generator(model,n_words,vocab,seed):\n","  result = text_to_seq(seed.split(\" \"),vocab).cuda()\n","  final_list = list(result)\n","  for n in range(n_words):\n","    #Instead of max sample\n","    #print(torch.tensor(final_list))\n","    val = model(torch.tensor(final_list).cuda())[0][0]\n","    val = sig(val)\n","    final_list.append(val.multinomial(num_samples=1))\n","  return tensor_to_str(final_list,vocab)\n","seed = \"estic\"\n","print(generator(LSTM_model,5,vocab,seed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdoPcpYo5-FX","executionInfo":{"status":"ok","timestamp":1655276284656,"user_tz":-120,"elapsed":202,"user":{"displayName":"JOSEP MONCLÚS CARRASCO","userId":"02130834910237115657"}},"outputId":"1f8ce9ad-2456-4dd2-8166-64ee0fc21d79"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":[" estic menu grinyolant germanivolament peculiar pets\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}]},{"cell_type":"code","source":["# Input / Output\n","#a mi m agraden els llibres perque soc / automata\n","\n","# el ocell / oest despatxava absorcions ficantse\n","\n","#tu ets / desplaent\n","\n","# tu ets / becker pressentia\n","\n","# nosaltres som / clausules meno ario molestaven emmidonats"],"metadata":{"id":"XKtZnJMmIqOC"},"execution_count":null,"outputs":[]}]}